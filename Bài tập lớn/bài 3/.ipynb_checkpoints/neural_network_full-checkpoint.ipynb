{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def mle(y, axis=1):\n",
    "    return np.argmax(y, axis)\n",
    "\n",
    "def L2_reg(lambda_, w1, w2):\n",
    "    return (lambda_ / 2.0) * (np.sum(w1 ** 2) + np.sum(w2 ** 2))\n",
    "\n",
    "\n",
    "def L1_reg(lambda_, w1, w2):\n",
    "    return (lambda_ / 2.0) * (np.abs(w1).sum() + np.abs(w2).sum())\n",
    "\n",
    "\n",
    "def cross_entropy(outputs, y_target):\n",
    "    return -np.sum(np.log(outputs) * y_target, axis=1)\n",
    "\n",
    "class NNClassifier:\n",
    "\n",
    "    def __init__(self, n_classes, n_features, n_hidden_units=30,\n",
    "                 l1=0.0, l2=0.0, epochs=500, learning_rate=0.01,\n",
    "                 n_batches=1, random_seed=None):\n",
    "\n",
    "        if random_seed:\n",
    "            np.random.seed(random_seed)\n",
    "        self.n_classes = n_classes\n",
    "        self.n_features = n_features\n",
    "        self.n_hidden_units = n_hidden_units\n",
    "        self.w1, self.w2 = self._init_weights()\n",
    "        self.l1 = l1\n",
    "        self.l2 = l2\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_batches = n_batches\n",
    "\n",
    "    def _init_weights(self):\n",
    "        w1 = np.random.uniform(-1.0, 1.0,\n",
    "                               size=(self.n_hidden_units, self.n_features))        \n",
    "        w2 = np.random.uniform(-1.0, 1.0,\n",
    "                               size=(self.n_classes, self.n_hidden_units))\n",
    "        return w1, w2\n",
    "      \n",
    "    def _forward(self, X):\n",
    "        net_input = X.copy()\n",
    "        net_hidden = self.w1.dot(net_input.T)\n",
    "        act_hidden = sigmoid(net_hidden)\n",
    "        net_out = self.w2.dot(act_hidden)\n",
    "        act_out = sigmoid(net_out)\n",
    "        return net_input, net_hidden, act_hidden, net_out, act_out\n",
    "    \n",
    "    def _backward(self, net_input, net_hidden, act_hidden, act_out, y):\n",
    "        sigma3 = act_out - y\n",
    "        sigma2 = self.w2.T.dot(sigma3) * sigmoid_prime(net_hidden)\n",
    "        grad1 = sigma2.dot(net_input)\n",
    "        grad2 = sigma3.dot(act_hidden.T)\n",
    "        return grad1, grad2      \n",
    "\n",
    "    def _error(self, y, output):\n",
    "        L1_term = L1_reg(self.l1, self.w1, self.w2)\n",
    "        L2_term = L2_reg(self.l2, self.w1, self.w2)\n",
    "        error = cross_entropy(output, y) + L1_term + L2_term\n",
    "        return 0.5 * np.mean(error)\n",
    "\n",
    "    def _backprop_step(self, X, y):\n",
    "        net_input, net_hidden, act_hidden, net_out, act_out = self._forward(X)\n",
    "        y = y.T\n",
    "\n",
    "        grad1, grad2 = self._backward(net_input, net_hidden, act_hidden, act_out, y)\n",
    "\n",
    "        # regularize\n",
    "        grad1 += (self.w1 * (self.l1 + self.l2))\n",
    "        grad2 += (self.w2 * (self.l1 + self.l2))\n",
    "\n",
    "        error = self._error(y, act_out)\n",
    "        \n",
    "        return error, grad1, grad2\n",
    "\n",
    "    def predict(self, X):\n",
    "        Xt = X.copy()\n",
    "        net_input, net_hidden, act_hidden, net_out, act_out = self._forward(Xt)\n",
    "        return mle(net_out.T)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        Xt = X.copy()\n",
    "        net_input, net_hidden, act_hidden, net_out, act_out = self._forward(Xt)\n",
    "        return softmax(act_out.T)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.error_ = []\n",
    "        X_data, y_data = X.copy(), y.copy()\n",
    "        y_data_enc = one_hot(y_data, self.n_classes)\n",
    "                \n",
    "        X_mbs = np.array_split(X_data, self.n_batches)\n",
    "        y_mbs = np.array_split(y_data_enc, self.n_batches)\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            \n",
    "            epoch_errors = []\n",
    "\n",
    "            for Xi, yi in zip(X_mbs, y_mbs):\n",
    "                \n",
    "                # update weights\n",
    "                error, grad1, grad2 = self._backprop_step(Xi, yi)\n",
    "                epoch_errors.append(error)\n",
    "                self.w1 -= (self.learning_rate * grad1)\n",
    "                self.w2 -= (self.learning_rate * grad2)\n",
    "            self.error_.append(np.mean(epoch_errors))\n",
    "        return self\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_hat = self.predict(X)\n",
    "        return np.sum(y == y_hat, axis=0) / float(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
